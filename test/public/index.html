<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Eleven Labs TTS &amp; STT Test</title>
  <style>
    * { box-sizing: border-box; }
    body {
      font-family: system-ui, -apple-system, sans-serif;
      max-width: 480px;
      margin: 2rem auto;
      padding: 0 1rem;
    }
    h1 { font-size: 1.25rem; margin-bottom: 1.5rem; }
    section { margin-bottom: 2rem; }
    section h2 { font-size: 1rem; margin-bottom: 0.75rem; color: #374151; }
    input[type="text"], textarea {
      width: 100%;
      padding: 0.5rem 0.75rem;
      border: 1px solid #d1d5db;
      border-radius: 6px;
      font-size: 1rem;
    }
    textarea { min-height: 80px; resize: vertical; }
    button {
      padding: 0.5rem 1rem;
      border-radius: 6px;
      font-size: 1rem;
      cursor: pointer;
      border: 1px solid #d1d5db;
      background: #f9fafb;
    }
    button:disabled { opacity: 0.6; cursor: not-allowed; }
    button.primary { background: #2563eb; color: #fff; border-color: #2563eb; }
    button.primary:hover:not(:disabled) { background: #1d4ed8; }
    button.mic { width: 56px; height: 56px; border-radius: 50%; padding: 0; }
    button.mic.listening { background: #fef2f2; border-color: #ef4444; color: #dc2626; }
    .status { font-size: 0.875rem; color: #6b7280; margin-top: 0.5rem; min-height: 1.25rem; }
    .transcript { margin-top: 0.5rem; padding: 0.5rem; background: #f3f4f6; border-radius: 6px; font-size: 0.875rem; }
    .row { display: flex; gap: 0.5rem; align-items: center; margin-top: 0.5rem; }
  </style>
</head>
<body>
  <h1>Eleven Labs TTS &amp; STT Test</h1>
  <p style="color:#6b7280;font-size:0.875rem;">Static test page â€” no Cloudflare. Uses <code>/api/tts</code> and <code>/ws/stt</code>.</p>

  <section>
    <h2>TTS â€” Text to speech</h2>
    <textarea id="ttsInput" placeholder="Enter text to speakâ€¦">Hello, this is a test of Eleven Labs text to speech.</textarea>
    <div class="row">
      <button id="ttsBtn" class="primary">Speak</button>
      <span id="ttsStatus" class="status"></span>
    </div>
  </section>

  <section>
    <h2>STT â€” Speech to text</h2>
    <div class="row">
      <button id="micBtn" class="mic" title="Click to start/stop listening">ðŸŽ¤</button>
      <span id="sttStatus" class="status"></span>
    </div>
    <div id="transcript" class="transcript" style="display:none;"></div>
  </section>

  <script>
    const SAMPLE_RATE = 16000;

    function toBase64(buffer) {
      const bytes = new Uint8Array(buffer);
      let bin = "";
      for (let i = 0; i < bytes.length; i++) bin += String.fromCharCode(bytes[i]);
      return btoa(bin);
    }

    // â€”â€”â€” TTS â€”â€”â€”
    const ttsInput = document.getElementById("ttsInput");
    const ttsBtn = document.getElementById("ttsBtn");
    const ttsStatus = document.getElementById("ttsStatus");

    ttsBtn.addEventListener("click", async () => {
      const text = ttsInput.value.trim();
      if (!text) {
        ttsStatus.textContent = "Enter some text.";
        return;
      }
      ttsBtn.disabled = true;
      ttsStatus.textContent = "Speakingâ€¦";
      try {
        const res = await fetch("/api/tts", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ text }),
        });
        if (!res.ok) {
          const err = await res.json().catch(() => ({}));
          ttsStatus.textContent = err.error || "TTS failed";
          return;
        }
        const blob = await res.blob();
        const url = URL.createObjectURL(blob);
        const audio = new Audio(url);
        audio.onended = () => {
          URL.revokeObjectURL(url);
          ttsStatus.textContent = "Done.";
          ttsBtn.disabled = false;
        };
        await audio.play();
      } catch (e) {
        ttsStatus.textContent = "Error: " + e.message;
        ttsBtn.disabled = false;
      }
    });

    // â€”â€”â€” STT â€”â€”â€”
    const micBtn = document.getElementById("micBtn");
    const sttStatus = document.getElementById("sttStatus");
    const transcriptEl = document.getElementById("transcript");

    let ws = null;
    let audioCtx = null;
    let worklet = null;
    let source = null;
    let stream = null;
    let committed = "";

    function stopListening() {
      worklet?.disconnect();
      source?.disconnect();
      stream?.getTracks().forEach((t) => t.stop());
      audioCtx?.close();
      ws?.close();
      stream = null;
      source = null;
      worklet = null;
      audioCtx = null;
      ws = null;
      micBtn.classList.remove("listening");
      micBtn.textContent = "ðŸŽ¤";
      sttStatus.textContent = "";
      transcriptEl.style.display = "none";
    }

    async function startListening() {
      try {
        stream = await navigator.mediaDevices.getUserMedia({
          audio: { echoCancellation: true, noiseSuppression: true, sampleRate: SAMPLE_RATE },
        });
      } catch {
        sttStatus.textContent = "Microphone access denied.";
        return;
      }

      audioCtx = new AudioContext({ sampleRate: SAMPLE_RATE });
      try {
        await audioCtx.audioWorklet.addModule("/audio-processor.js");
      } catch (e) {
        sttStatus.textContent = "Failed to load audio processor.";
        stream.getTracks().forEach((t) => t.stop());
        return;
      }

      source = audioCtx.createMediaStreamSource(stream);
      worklet = new AudioWorkletNode(audioCtx, "pcm-processor");
      const protocol = window.location.protocol === "https:" ? "wss:" : "ws:";
      ws = new WebSocket(protocol + "//" + window.location.host + "/ws/stt");
      committed = "";

      ws.onopen = () => {
        sttStatus.textContent = "Listeningâ€¦";
        transcriptEl.style.display = "block";
        transcriptEl.textContent = "";
      };

      ws.onmessage = (evt) => {
        try {
          const msg = JSON.parse(evt.data);
          if (msg.type === "partial_transcript") {
            transcriptEl.textContent = committed + (committed ? " " : "") + (msg.text || "");
          } else if (msg.type === "committed_transcript") {
            const t = msg.text || "";
            committed += (committed ? " " : "") + t;
            transcriptEl.textContent = committed;
          } else if (msg.type === "error") {
            sttStatus.textContent = "Error: " + (msg.message || "Unknown");
            stopListening();
          }
        } catch (_) {}
      };

      ws.onclose = () => {
        if (stream) stopListening();
      };

      worklet.port.onmessage = (e) => {
        if (ws && ws.readyState === WebSocket.OPEN) {
          ws.send(JSON.stringify({
            type: "input_audio_chunk",
            audioBase64: toBase64(e.data),
            sampleRate: audioCtx.sampleRate,
          }));
        }
      };

      source.connect(worklet);
      worklet.connect(audioCtx.destination);
      micBtn.classList.add("listening");
      micBtn.textContent = "â¹";
    }

    micBtn.addEventListener("click", () => {
      if (ws && ws.readyState === WebSocket.OPEN) {
        stopListening();
      } else {
        startListening();
      }
    });
  </script>
</body>
</html>
