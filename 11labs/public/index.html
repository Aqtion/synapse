<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ElevenLabs Demo</title>
  <style>
    *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }

    body {
      min-height: 100vh;
      background: #0a0a0f;
      color: #e8e8f0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      gap: 48px;
      padding: 32px;
    }

    h1 {
      font-size: 1.6rem;
      font-weight: 600;
      letter-spacing: -0.02em;
      color: #ffffff;
    }
    h1 span {
      background: linear-gradient(135deg, #6366f1, #a855f7);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
    }

    .card {
      background: #13131a;
      border: 1px solid #1e1e2e;
      border-radius: 20px;
      padding: 36px;
      width: 100%;
      max-width: 440px;
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 20px;
    }

    .card-label {
      font-size: 0.75rem;
      font-weight: 600;
      letter-spacing: 0.12em;
      text-transform: uppercase;
      color: #6366f1;
    }

    /* ── Mic button ─────────────────────────────────────────── */
    .mic-btn {
      width: 80px;
      height: 80px;
      border-radius: 50%;
      border: none;
      cursor: pointer;
      background: #1e1e2e;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: background 0.2s, transform 0.1s, box-shadow 0.2s;
    }
    .mic-btn:hover  { background: #252535; }
    .mic-btn:active { transform: scale(0.96); }
    .mic-btn.active {
      background: #2a1010;
      box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7);
      animation: pulse 1.4s ease-out infinite;
    }
    @keyframes pulse {
      0%   { box-shadow: 0 0 0 0   rgba(239, 68, 68, 0.7); }
      70%  { box-shadow: 0 0 0 18px rgba(239, 68, 68, 0);   }
      100% { box-shadow: 0 0 0 0   rgba(239, 68, 68, 0);   }
    }
    .mic-btn svg { width: 32px; height: 32px; }
    .mic-btn.active svg { stroke: #ef4444; }

    .mic-status {
      font-size: 0.85rem;
      color: #6b6b80;
      min-height: 1.2em;
      text-align: center;
    }
    .mic-status.live { color: #ef4444; }

    /* ── Transcript ──────────────────────────────────────────── */
    .transcript-wrap {
      width: 100%;
      min-height: 100px;
      background: #0e0e16;
      border: 1px solid #1e1e2e;
      border-radius: 12px;
      padding: 14px 16px;
      font-size: 0.95rem;
      line-height: 1.65;
      color: #e8e8f0;
    }

    .committed { color: #e8e8f0; }
    .partial   { color: #5a5a7a; font-style: italic; }

    .placeholder {
      color: #3a3a50;
      font-style: italic;
    }

    /* cursor blink when live */
    .cursor {
      display: inline-block;
      width: 2px;
      height: 1em;
      background: #6366f1;
      vertical-align: text-bottom;
      margin-left: 2px;
      animation: blink 1s step-end infinite;
    }
    @keyframes blink { 0%,100%{opacity:1} 50%{opacity:0} }

    /* ── TTS button ──────────────────────────────────────────── */
    .tts-btn {
      width: 100%;
      padding: 14px 24px;
      border: none;
      border-radius: 12px;
      cursor: pointer;
      background: linear-gradient(135deg, #6366f1, #a855f7);
      color: #fff;
      font-size: 0.95rem;
      font-weight: 600;
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 10px;
      transition: opacity 0.2s, transform 0.1s;
    }
    .tts-btn:hover    { opacity: 0.88; }
    .tts-btn:active   { transform: scale(0.98); }
    .tts-btn:disabled { opacity: 0.45; cursor: not-allowed; }
    .tts-btn svg { width: 20px; height: 20px; flex-shrink: 0; }

    .tts-quote {
      font-size: 0.8rem;
      color: #4a4a60;
      text-align: center;
      font-style: italic;
      line-height: 1.5;
    }
  </style>
</head>
<body>

  <h1>Eleven<span>Labs</span> Demo</h1>

  <!-- ── Speech to Text ──────────────────────────────────── -->
  <div class="card">
    <div class="card-label">Real-time Speech to Text</div>

    <button class="mic-btn" id="micBtn" title="Toggle microphone">
      <svg id="micIcon" viewBox="0 0 24 24" fill="none" stroke="#a0a0c0"
           stroke-width="1.8" stroke-linecap="round" stroke-linejoin="round">
        <rect x="9" y="2" width="6" height="12" rx="3"/>
        <path d="M5 10a7 7 0 0 0 14 0"/>
        <line x1="12" y1="19" x2="12" y2="22"/>
        <line x1="8" y1="22" x2="16" y2="22"/>
      </svg>
    </button>

    <div class="mic-status" id="micStatus">Click to start listening</div>

    <div class="transcript-wrap" id="transcriptWrap">
      <span class="placeholder" id="placeholder">Transcript will appear here in real-time…</span>
    </div>
  </div>

  <!-- ── Text to Speech ──────────────────────────────────── -->
  <div class="card">
    <div class="card-label">Text to Speech</div>

    <button class="tts-btn" id="ttsBtn">
      <svg viewBox="0 0 24 24" fill="none" stroke="currentColor"
           stroke-width="1.8" stroke-linecap="round" stroke-linejoin="round">
        <polygon points="11 5 6 9 2 9 2 15 6 15 11 19 11 5"/>
        <path d="M19.07 4.93a10 10 0 0 1 0 14.14"/>
        <path d="M15.54 8.46a5 5 0 0 1 0 7.07"/>
      </svg>
      Play Hardcoded Statement
    </button>

    <div class="tts-quote">
      "Hello! This is a hardcoded message from ElevenLabs text to speech. Pretty cool, right?"
    </div>
  </div>

  <script>
    // ═══════════════════════════════════════════════════════
    //  Real-time Speech-to-Text
    // ═══════════════════════════════════════════════════════
    const micBtn       = document.getElementById("micBtn");
    const micStatus    = document.getElementById("micStatus");
    const transcriptWrap = document.getElementById("transcriptWrap");
    const placeholder  = document.getElementById("placeholder");

    let isListening   = false;
    let ws            = null;
    let audioCtx      = null;
    let workletNode   = null;
    let micSource     = null;
    let micStream     = null;

    // Track what's been committed (final) vs the current partial
    let committedText = "";

    function renderTranscript(partial = "") {
      if (!committedText && !partial) {
        transcriptWrap.innerHTML = `<span class="placeholder">Transcript will appear here in real-time…</span>`;
        return;
      }

      const committedHtml = committedText
        ? `<span class="committed">${escHtml(committedText)}</span>`
        : "";

      const partialHtml = partial
        ? `<span class="partial">${escHtml(partial)}</span>`
        : "";

      const cursorHtml = isListening ? `<span class="cursor"></span>` : "";

      transcriptWrap.innerHTML = committedHtml + partialHtml + cursorHtml;
      transcriptWrap.scrollTop = transcriptWrap.scrollHeight;
    }

    function escHtml(s) {
      return s.replace(/&/g,"&amp;").replace(/</g,"&lt;").replace(/>/g,"&gt;");
    }

    function toBase64(buffer) {
      const bytes = new Uint8Array(buffer);
      let bin = "";
      for (let i = 0; i < bytes.length; i++) bin += String.fromCharCode(bytes[i]);
      return btoa(bin);
    }

    async function startListening() {
      try {
        micStream = await navigator.mediaDevices.getUserMedia({
          audio: { echoCancellation: true, noiseSuppression: true, sampleRate: 16000 },
        });
      } catch {
        micStatus.textContent = "Microphone access denied.";
        return;
      }

      // AudioContext at 16 kHz so no resampling needed
      audioCtx = new AudioContext({ sampleRate: 16000 });
      await audioCtx.audioWorklet.addModule("/audio-processor.js");

      micSource  = audioCtx.createMediaStreamSource(micStream);
      workletNode = new AudioWorkletNode(audioCtx, "pcm-processor");

      // Open WebSocket to our Bun proxy
      ws = new WebSocket(`ws://${location.host}/ws/stt`);
      ws.binaryType = "arraybuffer";

      ws.onopen = () => {
        micStatus.textContent = "Listening…";
        micStatus.classList.add("live");
      };

      ws.onmessage = (evt) => {
        let msg;
        try { msg = JSON.parse(evt.data); } catch { return; }

        if (msg.type === "partial_transcript") {
          renderTranscript(msg.text ?? "");
        } else if (msg.type === "committed_transcript") {
          committedText += (committedText ? " " : "") + (msg.text ?? "");
          renderTranscript("");
        } else if (msg.type === "error") {
          micStatus.textContent = `Error: ${msg.message}`;
          stopListening();
        }
      };

      ws.onclose = () => {
        if (isListening) stopListening();
      };

      // Send PCM16 chunks — format the server + ElevenLabs SDK expect
      workletNode.port.onmessage = (e) => {
        if (ws && ws.readyState === WebSocket.OPEN) {
          ws.send(JSON.stringify({
            type: "input_audio_chunk",
            audioBase64: toBase64(e.data),
            sampleRate: audioCtx.sampleRate,
          }));
        }
      };

      micSource.connect(workletNode);
      workletNode.connect(audioCtx.destination); // silent passthrough

      isListening = true;
      micBtn.classList.add("active");
      renderTranscript("");
    }

    function stopListening() {
      isListening = false;
      micBtn.classList.remove("active");
      micStatus.textContent = "Click to start listening";
      micStatus.classList.remove("live");

      workletNode?.disconnect();
      micSource?.disconnect();
      micStream?.getTracks().forEach(t => t.stop());
      audioCtx?.close();
      ws?.close();

      ws = workletNode = micSource = micStream = audioCtx = null;
      renderTranscript(""); // finalize display (no cursor)
    }

    micBtn.addEventListener("click", () => {
      if (!isListening) startListening();
      else stopListening();
    });


    // ═══════════════════════════════════════════════════════
    //  Text-to-Speech (hardcoded statement)
    // ═══════════════════════════════════════════════════════
    const ttsBtn = document.getElementById("ttsBtn");

    ttsBtn.addEventListener("click", async () => {
      ttsBtn.disabled = true;
      ttsBtn.querySelector("svg + *")?.remove();
      ttsBtn.insertAdjacentText("beforeend", " Loading…");

      try {
        const res = await fetch("/api/tts");
        if (!res.ok) throw new Error("TTS request failed");
        const blob = await res.blob();
        const url  = URL.createObjectURL(blob);
        const audio = new Audio(url);
        audio.onended = () => URL.revokeObjectURL(url);
        audio.play();
      } catch {
        alert("Failed to load speech. Check the server logs.");
      } finally {
        ttsBtn.disabled = false;
        ttsBtn.innerHTML = `
          <svg viewBox="0 0 24 24" fill="none" stroke="currentColor"
               stroke-width="1.8" stroke-linecap="round" stroke-linejoin="round"
               style="width:20px;height:20px;flex-shrink:0">
            <polygon points="11 5 6 9 2 9 2 15 6 15 11 19 11 5"/>
            <path d="M19.07 4.93a10 10 0 0 1 0 14.14"/>
            <path d="M15.54 8.46a5 5 0 0 1 0 7.07"/>
          </svg>
          Play Hardcoded Statement`;
      }
    });
  </script>
</body>
</html>
